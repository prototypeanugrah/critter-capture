{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Dataset Creation\n",
    "This notebook builds a representative sample dataset of 2,000 observations from the full dataset at `../data/data.csv`. It preserves the distribution of the `iconic_taxon_name` field so the sample mimics the original class balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('..') / 'data' / 'data.csv'\n",
    "OUTPUT_PATH = Path('..') / 'data' / 'sample_data.csv'\n",
    "SAMPLE_SIZE = 2000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rows_grouped(path):\n",
    "    grouped = defaultdict(list)\n",
    "    header = None\n",
    "    with path.open(newline='') as handle:\n",
    "        reader = csv.DictReader(handle)\n",
    "        header = reader.fieldnames\n",
    "        for row in reader:\n",
    "            grouped[row.get('iconic_taxon_name') or 'UNKNOWN'].append(row)\n",
    "    if not header:\n",
    "        raise RuntimeError('Input CSV appears to be empty or missing header.')\n",
    "    return header, grouped\n",
    "\n",
    "def largest_remainder_allocation(group_counts, total_size):\n",
    "    total_rows = sum(group_counts.values())\n",
    "    allocations = {}\n",
    "    remainders = []\n",
    "    allocated = 0\n",
    "    for category, count in group_counts.items():\n",
        "        raw = total_size * count / total_rows\n",
    "        base = math.floor(raw)\n",
    "        allocations[category] = base\n",
    "        allocated += base\n",
    "        remainders.append((raw - base, category))\n",
    "    remaining = total_size - allocated\n",
    "    remainders.sort(reverse=True)\n",
    "    for idx in range(remaining):\n",
    "        frac, category = remainders[idx]\n",
    "        allocations[category] += 1\n",
    "    return allocations\n",
    "\n",
    "def stratified_sample(grouped_rows, header, output_path, total_size):\n",
    "    counts = {category: len(rows) for category, rows in grouped_rows.items()}\n",
    "    if total_size > sum(counts.values()):\n",
    "        raise ValueError('Requested sample size exceeds available rows.')\n",
    "    allocations = largest_remainder_allocation(counts, total_size)\n",
    "    selected = []\n",
    "    for category, rows in grouped_rows.items():\n",
    "        need = allocations.get(category, 0)\n",
    "        if need:\n",
    "            selected.extend(random.sample(rows, need))\n",
    "    random.shuffle(selected)\n",
    "    with output_path.open('w', newline='') as handle:\n",
    "        writer = csv.DictWriter(handle, fieldnames=header)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(selected)\n",
    "    return selected, allocations\n",
    "\n",
    "header, grouped_rows = load_rows_grouped(DATA_PATH)\n",
    "original_counts = Counter({category: len(rows) for category, rows in grouped_rows.items()})\n",
    "sampled_rows, allocation = stratified_sample(grouped_rows, header, OUTPUT_PATH, SAMPLE_SIZE)\n",
    "sampled_counts = Counter(row.get('iconic_taxon_name') or 'UNKNOWN' for row in sampled_rows)\n",
    "\n",
    "print(f'Wrote {len(sampled_rows)} rows to {OUTPUT_PATH}')\n",
    "print('\\nOriginal distribution:')\n",
    "for category, count in original_counts.most_common():\n",
    "    print(f'  {category}: {count}')\n",
    "print('\\nSample distribution:')\n",
    "for category, count in sampled_counts.most_common():\n",
    "    print(f'  {category}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First five sampled rows:')\n",
    "for row in sampled_rows[:5]:\n",
    "    print({key: row[key] for key in ('id', 'iconic_taxon_name', 'common_name', 'scientific_name')})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
